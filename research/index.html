<!DOCTYPE html>
<html>
  <head>
    <title>Archiki Prasad</title>

        <meta charset="utf-8" />
    <meta content='text/html; charset=utf-8' http-equiv='Content-Type'>
    <meta http-equiv='X-UA-Compatible' content='IE=edge'>
    <meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1.0'>

    
    <meta name="description" content="Electrical Engineering Dual-Degree Student, IIT Bombay">
    <meta property="og:description" content="Electrical Engineering Dual-Degree Student, IIT Bombay" />
    
    <meta name="author" content="Archiki Prasad" />

    

    <!--[if lt IE 9]>
      <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="alternate" type="application/rss+xml" title="Archiki Prasad - Electrical Engineering Dual-Degree Student, IIT Bombay" href="/feed.xml" />

    <!-- Created with Jekyll Now - http://github.com/barryclark/jekyll-now -->
  </head>

  <body>
    <div class="wrapper-masthead">
      <div class="container">
        <header class="masthead clearfix">
          
          <div class="site-info">
            <h1 class="site-name"><a href="/">Archiki Prasad</a></h1>
            <p class="site-description">Electrical Engineering Dual-Degree Student, IIT Bombay</p>
          </div>

          <nav>
            <a href="/about">About</a>
            <a href="/research">Research</a>
            <a href="/files/Resume.pdf">Resume</a>
            <a href="/files/CV_final.pdf">CV</a>
          </nav>
        </header>
      </div>
    </div>


    <div id="main" role="main" class="container">
      <article class="post">
  <h1>Research</h1>

  <div class="entry">
    <p>My research interests broadly lie in the fields of Machine Learning, Automatic  Speech Recognition and Natural Language Processing. In the past I have worked on time-series and sequence-to-sequence tasks. I am interested in explainability and interpretability of black box models in Automatic Speech Recognition and Natural Language Processing. Recently, I have been fascinated by problems around context in converstational and dialogue systems. </p>

<h2 id="publications">Publications and Patents</h2>

<ul>
  <li>
    <b><a href="https://www.aclweb.org/anthology/2020.acl-main.345.pdf">How Accents Confound: Probing for Accent Information in End-to-End Speech Recognition Systems</a></b><br />
 <strong>Archiki Prasad</strong> and Preethi Jyothi<br />
 <b><a href="https://www.aclweb.org/anthology/volumes/2020.acl-main/">ACL 2020</a></b><br /> 
[<a href="#archiki_acl20_bib">bib</a>]
[<a href="#" onclick="$('#archiki_acl20_abstract').toggle();return false;">abstract</a>]                          
[<a href="https://github.com/archiki/ASR-Accent-Analysis">code</a>] [<a href="https://slideslive.com/38929438/how-accents-confound-probing-for-accent-information-in-endtoend-speech-recognition-systems">talk</a>]
<div id="archiki_acl20_bib" class="abstract" style="display:none;">
                            <!-- </br> -->
<pre>
@inproceedings{prasad2020accents,
  title={How Accents Confound: Probing for Accent Information in End-to-End Speech Recognition Systems},
  author={Prasad, Archiki and Jyothi, Preethi},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={3739--3753},
  year={2020}
}
}

</pre>
</div>
<div id="archiki_acl20_abstract" class="abstract" style="display:none;">
</br>
    <p>
        In this work, we present a detailed analysis of how accent information is reflected in the internal representation of speech in an end-to-end automatic speech recognition (ASR) system. We use a state-of-the-art end-to-end ASR system, comprising convolutional and recurrent layers, that is trained on a large amount of US-accented English speech and evaluate the model on speech samples from seven different English accents. We examine the effects of accent on the internal representation using three main probing techniques: a) Gradient-based explanation methods, b) Information-theoretic measures, and c) Outputs of accent and phone classifiers. We find different accents exhibiting similar trends irrespective of the probing technique used. We also find that most accent information is encoded within the first recurrent layer, which is suggestive of how one could adapt such an end-to-end model to learn representations that are invariant to accents.
    </p>
</div>
<!-- </p> -->

  </li>
  <li>
    <p><b><a href="https://dl.acm.org/doi/pdf/10.1145/3366424.3382728">Time Series Forecasting for Cold-Start Items by Learning from Related Items using Memory Networks</a></b><br />
Ayush Chauhan, <strong>Archiki Prasad</strong>, Parth Gupta, Amiredddy Prashanth Reddy and Shiv Kumar Saini<br />
<b><a href="https://www2020.thewebconf.org/">The Web Conference (WWW) 2020 </a></b><br /> 
<!-- [<a href="https://dl.acm.org/doi/pdf/10.1145/3366424.3382728">pdf</a>] </p> -->
  </li>
  <li>
    <p><b>Key-Value Memory Networks for Predicting Time Series Metrics of Target Entities</b><br />
Ayush Chauhan, <strong>Archiki Prasad</strong>, Parth Gupta, Ritwick Chaudhary, Amiredddy Prashanth Reddy and Shiv Kumar Saini<br />
<em>Patent filed at the <a href="https://www.uspto.gov/">US Patent and Trademarks Office</a>, 2020</em><br />
[Application No. US16/868942] </p>
  </li>
  <li>
    <p><b>Decentralized Age-of-Information Bandits</b><br />
<strong>Archiki Prasad</strong>, Vishal Jain and Sharayu Moharir<br />
<em>submitted to IEEE-<a href="https://wcnc2021.ieee-wcnc.org/">Wireless Communications and Networking Conference (WCNC), 2021</a></em><br /> 
[<a href='https://arxiv.org/abs/2009.12961'>pre-print</a>]  [submission available on request]</p>
  </li>
</ul>

<!-- <p><sup>†</sup><em>Equal Contribution</em></p> -->

<h2 id="research-projects">Research Projects</h2>
Updating Soon!

<!-- <h3 id="2019">2019</h3> -->

<!-- <p><strong>Learning with Noisy Sequence Labels</strong><br />
<em>Bachelor’s Thesis guided by <a href="https://www.cse.iitb.ac.in/~pjyothi/">Prof. Preethi Jyothi</a></em></p>

<p>Majority of the datasets collected by crowdsourcing tend to have noisy labels. Although there is a lot of theoretical and empirical work for learning with noisy labels for multiclass classification, there is very sparse work for structured outputs such as sequences. We are currently working on the problem of probablistic label aggregation for tasking involving sequences such as Part of Speech tagging and Named Entity Recognition.</p>

<p><strong>Policy Iteration Lower Bounds for Multi-Action MDPs</strong> <a href="https://joshinh.github.io/files/CS747_report.pdf">[report]</a><br />
<em>Guide: <a href="https://www.cse.iitb.ac.in/~shivaram/">Prof. Shivaram K</a> (Course Project)</em></p>

<p>Simple Policy Iteration is a type of policy iteration algorithm where the policy of only one improvable state is changed at every step. <a href="https://pdfs.semanticscholar.org/b321/9edc2ce55b2d7f5d45cc014a0d2733ed3051.pdf">Melekopoglou and Condon</a> showed an exponential lower bound for 2-action MDPs. We generalized the MDPs to k-actions and demonstrate a lower bound of O(k.exp(n)).</p>

<p><strong>Explainable Natural Language Inference</strong><br />
<em>Guide: <a href="http://www.nec-labs.com/christopher-malon">Dr. Christopher Malon</a> (Internship at NEC Labs, Princeton)</em></p>

<p>Simple entailment models try to judge the hypotheses as true, false, or unsupported based on information in a single sentence or group of concatenated sentences, but this information is sometimes insufficient. We constructed datasets for multi-hop NLI by transforming existing multi-hop QA datasets and proposed models which could perform multi-hop reasoning. Our model could also generate explanations for the inferential relationship without any direct supervision.</p>

<h3 id="2018">2018</h3>

<p><strong>Interpretable Multi-hop Reading Comprehension</strong> <a href="https://www.aclweb.org/anthology/P19-1261/">[paper]</a> <br />
<em>Guide: <a href="">Prof. Mohit Bansal</a> (Internship at UNC Chapel Hill)</em></p>

<p>Built interpretable models for multi-hop reading comprehension which searched and assembled important contextual information, by constructing a tree of reasoning chains to answer a given question. By constructing explicit reasoning chains, it was possible to understand the exact evidence used by the model. Achieved strong results on two challenging datasets and also demonstrated the interpretability through various analysis and ablations.</p>

<p><strong>Cross-lingual Question Generation</strong> <a href="https://www.aclweb.org/anthology/P19-1481/">[paper]</a><br />
<em>Guide: <a href="https://www.cse.iitb.ac.in/~ganesh/">Prof. Ganesh Ramakrishnan</a> and <a href="https://www.cse.iitb.ac.in/~pjyothi/">Prof. Preethi Jyothi</a></em></p>

<p>Many Natural Language Generation tasks assume access to large supervised datasets which may not be available for all languages. We proposed cross-lingual pre-training methods which could leverage information from data rich languages (such as English) to improve performance on the downstream task for low resource languages (such as Hindi). We also released a small Hindi QA dataset along with the work.</p>

<p><strong>Accent Adaptation for Speech Recognition</strong> <a href="https://joshinh.github.io/files/RnD_Report.pdf">[report]</a> <br />
<em>Guide: <a href="https://www.cse.iitb.ac.in/~pjyothi/">Prof. Preethi Jyothi</a></em></p>

<p>Majority of the state-of-the-art automatic speech recognition (ASR) systems for English are trained on the readily available US-accented data and perform poorly on other accents. We introduced domain adversarial training techniques to adapt ASR systems to low resource accents. Extended this work (later in 2019) by proposing a novel coupled training paradigm which exploited speech data with same text content. Our method gave huge gains in performance on heavy accents such as Indian.</p> -->

  </div>

  <!--div class="date">
    Written on 
  </div
//-->

  
</article>
</div>

    <div class="wrapper-footer">
      <div class="container">
        <footer class="footer">
<!-- <div style="float:left;color:#808080">Archiki Prasad<br style="clear:both" /> </div> -->
<div class="row">
<div class="column"><a style="float:left;color:#808080">Archiki Prasad</a>
<br style="clear:both" />
<a href="mailto:archikiprasad@gmail.com" style="float:left;">archikiprasad@gmail.com</a>
<br style="clear:both" />
<a href="mailto:archiki@iitb.ac.in" style="float:left;">archiki@iitb.ac.in</a>
</div>
<!-- <div class="row"> -->
<div class="column">
<a href="https://github.com/archiki" style="float:left;"><span class="icon icon--github"><svg x="0px" y="0px" width="16px" height="16px" viewBox="0 0 16 16"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">archiki</span></a>
<br style="clear:both" />
<a href="https://www.linkedin.com/in/archiki-prasad" style="float:left;"><span class="icon icon--linkedin"><svg  x="0px" y="0px" width="16px" height="16px" viewBox="0 -20 512 512"><path fill="#828282" d="M150.65,100.682c0,27.992-22.508,50.683-50.273,50.683c-27.765,0-50.273-22.691-50.273-50.683
    C50.104,72.691,72.612,50,100.377,50C128.143,50,150.65,72.691,150.65,100.682z M143.294,187.333H58.277V462h85.017V187.333z
    M279.195,187.333h-81.541V462h81.541c0,0,0-101.877,0-144.181c0-38.624,17.779-61.615,51.807-61.615
    c31.268,0,46.289,22.071,46.289,61.615c0,39.545,0,144.181,0,144.181h84.605c0,0,0-100.344,0-173.915
    s-41.689-109.131-99.934-109.131s-82.768,45.369-82.768,45.369V187.333z"/></svg></span><span class="username">&nbsp;Archiki Prasad</span></a>
<br style="clear:both" />
<a href="https://www.facebook.com/archiki1407" style="float:left;"><span class="icon icon--facebook"><svg x="0px" y="0px" width="16px" height="16px" viewBox="0 0 20 20"><path fill="#828282" d="M11.344,5.71c0-0.73,0.074-1.122,1.199-1.122h1.502V1.871h-2.404c-2.886,0-3.903,1.36-3.903,3.646v1.765h-1.8V10h1.8v8.128h3.601V10h2.403l0.32-2.718h-2.724L11.344,5.71z"></path>
</svg></span><span class="username">&nbsp;archiki1407</span></a>
</div>
</div>

        </footer>
      </div>
    </div>

    

  </body>
</html>

