<!DOCTYPE html>
<html>
  <head>
    <title>Archiki Prasad</title>
    <base target="_blank">
        <meta charset="utf-8" />
    <meta content='text/html; charset=utf-8' http-equiv='Content-Type'>
    <meta http-equiv='X-UA-Compatible' content='IE=edge'>
    <meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1.0'>

    
    <!-- <meta name="description" content="Electrical Engineering Dual-Degree Student, IIT Bombay">
    <meta property="og:description" content="Electrical Engineering Dual-Degree Student, IIT Bombay" /> -->
    
    <meta name="author" content="Archiki Prasad" />

    

    <!--[if lt IE 9]>
      <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <link rel="stylesheet" type="text/css" href="/style.css" />
<!--     <link href="https://fonts.googleapis.com/css?family=Roboto+Slab:300,400,700" rel="stylesheet"> -->
    <link href="https://fonts.googleapis.com/css?family=Ubuntu:300,400,300italic,400italic|Raleway:500,100,300" rel="stylesheet">
    <link rel="alternate" type="application/rss+xml" title="Archiki Prasad - PhD Student in Computer Science, UNC Chapel Hill" href="/feed.xml" />
    <link rel="icon" type="image/png" href="/files/UNC.png">
    <!-- Created with Jekyll Now - http://github.com/barryclark/jekyll-now -->
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
        <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
  </head>

  <body>
    <div class="wrapper-masthead">
      <div class="container">
        <header class="masthead clearfix">
          
          <div class="site-info">
            <h1 class="site-name"><a href="/" target="_self">Archiki Prasad</a></h1>
            <!-- <p class="site-description">Electrical Engineering Dual-Degree Student, IIT Bombay</p> -->
          </div>

          <nav>
            <a href="/about" target="_self">About</a>
            <a href="/research" target="_self">Research</a>
            <a href="/files/CV.pdf">CV</a>
          </nav>
        </header>
      </div>
    </div>

<!-- <div id="archiki_acl20_bib" class="entry" style="display:none;">  -->
                           <!-- </br>
<pre>
@inproceedings{prasad2020accents,
  title={How Accents Confound: Probing for Accent Information in End-to-End Speech Recognition Systems},
  author={Prasad, Archiki and Jyothi, Preethi},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={3739--3753},
  year={2020}
}
}
</pre>
</div> -->
    <div id="main" role="main" class="container">
      <article class="post">
  <h1>Research</h1>

  <div class="entry">
    <p>My research interests broadly lie in the fields of Natural Language Processing and Machine Learning.My primary research goals are (1) developing effective ways of evaluating reasoning over natural language, and (2) leveraging as well as improving Large Language Models’ (LLMs) reasoning capabilities to perform complex tasks requiring compositional generalization, planning abilities and enhancing downstream performance.  I seek to develop methods that enable LLMs to identify and rectify issues in their reasoning, as well as to enhance their understanding of the reasoning process. I also explore practical applications of LLM reasoning in domains such as planning and coding. </p>

<h3 id="publications">Publications and Patents [<a href="https://scholar.google.com/citations?user=Svcwv-IAAAAJ&hl=en">Google Scholar</a>] [<a href="https://www.semanticscholar.org/author/Archiki-Prasad/1677896557">Semantic Scholar</a>]</h3> 

<ul>
  <li>
    <p><b><a href="https://arxiv.org/abs/2411.04109">Self-Consistency Preference Optimization</a></b><br/>
<strong>Archiki Prasad</strong>,  Weizhe Yuan, Richard Yuanzhe Pang, Jing Xu, Maryam Fazel-Zarandi, Mohit Bansal, Sainbayar Sukhbaatar, Jason Weston, Jane Yu <br />
<b>Arxiv Preprint</b><br /> 
[<a href="#" onclick="$('#archiki_scpo24_abstract').toggle();return false;" style="font-variant: small-caps;">abstract</a>] 
<div id="archiki_scpo24_abstract" class="abstract" style="display:none;">
</br>
    <p>
      Self-alignment, whereby models learn to improve themselves without human annotation, is a rapidly growing research area. However, existing techniques often fail to improve complex reasoning tasks due to the difficulty of assigning correct rewards. An orthogonal approach that is known to improve correctness is self-consistency, a method applied at inference time based on multiple sampling in order to find the most consistent answer. In this work, we extend the self-consistency concept to help train models. We thus introduce self-consistency preference optimization (ScPO), which iteratively trains consistent answers to be preferred over inconsistent ones on unsupervised new problems. We show ScPO leads to large improvements over conventional reward model training on reasoning tasks such as GSM8K and MATH, closing the gap with supervised training with gold answers or preferences, and that combining ScPO with standard supervised learning improves results even further. On ZebraLogic, ScPO finetunes Llama-3 8B to be superior to Llama-3 70B, Gemma-2 27B, and Claude-3 Haiku.
  <li>
    <p><b><a href="https://arxiv.org/abs/2410.01735">LASeR: Learning to Adaptively Select Reward Models with Multi-Armed Bandits</a></b><br/>
Duy Nguyen*, <strong>Archiki Prasad*</strong>, Swarnadeep Saha, Elias Stengel-Eskin, and Mohit Bansal<br />
<b>Arxiv Preprint</b><br /> 
[<a href="#" onclick="$('#archiki_laser24_abstract').toggle();return false;" style="font-variant: small-caps;">abstract</a>] [<a href="https://github.com/duykhuongnguyen/LASeR-MAB" style="font-variant: small-caps;">code</a>] 
<div id="archiki_laser24_abstract" class="abstract" style="display:none;">
</br>
    <p>
Reward Models (RMs) play a crucial role in aligning LLMs with human preferences, enhancing their performance by ranking outputs during inference or iterative training. However, the degree to which an RM generalizes to new tasks is often not known a priori (e.g. some RMs may excel at scoring creative writing vs. math reasoning). Therefore, using only one fixed RM while training LLMs can be suboptimal. Moreover, optimizing LLMs with multiple RMs simultaneously can be prohibitively computationally-intensive and challenging due to conflicting signals from different RMs, potentially degrading performance. To address these challenges, we introduce LASeR (Learning to Adaptively Select Rewards), which iteratively trains LLMs using multiple RMs, selecting and utilizing the most well-suited RM for each instance to rank outputs and generate preference data, framed as a multi-armed bandit problem. Our results on commonsense and math reasoning tasks demonstrate that LASeR can boost iterative LLM optimization by optimizing for multiple RMs, improving the absolute average accuracy of Llama-3-8B over three datasets by 2.67% over training with ensemble RM scores while also showing superior training efficiency (e.g., a 2x speedup). Moreover, on WildChat, a benchmark of instruction-following prompts, we find that using Llama-3-8B LASeR leads to a 71.45% AlpacaEval win rate over sequentially optimizing multiple RMs. Extending to long-context generation tasks, we find that on Llama-3-8B, LASeR achieves an average improvement of 2.64 F1 and 2.42 F1 on single- and multi-document QA over random RM selection when used with best-of-n sampling. LASeR is robust to noisy rewards and generalizes to multiple settings. Finally, LASeR's RM selection changes depending on the underlying task or instance and we verify the presence of conflicting preferences from multiple RMs that can be mitigated using LASeR.  
  <li>
    <p><b><a href="https://arxiv.org/abs/2409.12147">MAgICoRe: Multi-Agent, Iterative, Coarse-to-Fine Refinement for Reasoning</a></b><br/>
Justin Chih-Yao Chen, <strong>Archiki Prasad</strong>, Swarnadeep Saha, Elias Stengel-Eskin, and Mohit Bansal<br />
<b>Arxiv Preprint</b><br /> 
[<a href="#" onclick="$('#archiki_magi24_abstract').toggle();return false;" style="font-variant: small-caps;">abstract</a>] [<a href="https://github.com/dinobby/MAgICoRe" style="font-variant: small-caps;">code</a>] 
<div id="archiki_magi24_abstract" class="abstract" style="display:none;">
</br>
    <p>
Large Language Models' (LLM) reasoning can be improved using test-time aggregation strategies, i.e., generating multiple samples and voting among generated samples. While these improve performance, they often reach a saturation point. Refinement offers an alternative by using LLM-generated feedback to improve solution quality. However, refinement introduces 3 key challenges: (1) Excessive refinement: Uniformly refining all instances can over-correct and reduce the overall performance. (2) Inability to localize and address errors: LLMs have a limited ability to self-correct and struggle to identify and correct their own mistakes. (3) Insufficient refinement: Deciding how many iterations of refinement are needed is non-trivial, and stopping too soon could leave errors unaddressed. To tackle these issues, we propose MAgICoRe, which avoids excessive refinement by categorizing problem difficulty as easy or hard, solving easy problems with coarse-grained aggregation and hard ones with fine-grained and iterative multi-agent refinement. To improve error localization, we incorporate external step-wise reward model (RM) scores. Moreover, to ensure effective refinement, we employ a multi-agent loop with three agents: Solver, Reviewer (which generates targeted feedback based on step-wise RM scores), and the Refiner (which incorporates feedback). To ensure sufficient refinement, we re-evaluate updated solutions, iteratively initiating further rounds of refinement. We evaluate MAgICoRe on Llama-3-8B and GPT-3.5 and show its effectiveness across 5 math datasets. Even one iteration of MAgICoRe beats Self-Consistency by 3.4%, Best-of-k by 3.2%, and Self-Refine by 4.0% while using less than half the samples. Unlike iterative refinement with baselines, MAgICoRe continues to improve with more iterations. Finally, our ablations highlight the importance of MAgICoRe's RMs and multi-agent communication.  
  <li>
    <p><b><a href="https://arxiv.org/abs/2409.07394">AdaCAD: Adaptively Decoding to Balance Conflicts between Contextual and Parametric Knowledge</a></b><br/>
Han Wang, <strong>Archiki Prasad</strong>, Elias Stengel-Eskin, and Mohit Bansal<br />
<b>Arxiv Preprint</b><br /> 
[<a href="#" onclick="$('#archiki_ada24_abstract').toggle();return false;" style="font-variant: small-caps;">abstract</a>] [<a href="https://github.com/HanNight/AdaCAD" style="font-variant: small-caps;">code</a>] 
<div id="archiki_ada24_abstract" class="abstract" style="display:none;">
</br>
    <p>
Knowledge conflict arises from discrepancies between information in the context of a large language model (LLM) and the knowledge stored in its parameters. This can hurt performance when using standard decoding techniques, which tend to ignore the context. Existing test-time contrastive methods seek to address this by comparing the LLM's output distribution with and without the context and adjust the model according to the contrast between them. However, we find that these methods frequently misjudge the degree of conflict and struggle to handle instances that vary in their amount of conflict, with static methods over-adjusting when conflict is absent. We propose a fine-grained, instance-level approach called AdaCAD, which dynamically infers the weight of adjustment based on the degree of conflict, as measured by the Jensen-Shannon divergence between distributions representing contextual and parametric knowledge. Our experiments across four models on six diverse question-answering (QA) datasets and three summarization tasks demonstrate that our training-free adaptive method consistently outperforms other decoding methods on QA, with average accuracy gains of 14.21% (absolute) over a static contrastive baseline, and improves the factuality of summaries by 5.59 (AlignScore). Furthermore, our analysis shows that while decoding with contrastive baselines hurts performance when conflict is absent, AdaCAD mitigates these losses, making it more applicable to real-world datasets in which some examples have conflict and others do not.  </li>
  <li>
    <p><b><a href="https://arxiv.org/abs/2407.14414">System-1.x: Learning to Balance Fast and Slow Planning with Language Models</a></b><br/>
Swarnadeep Saha, <strong>Archiki Prasad</strong>, Justin Chih-Yao Chen, Peter Hase, Elias Stengel-Eskin, and Mohit Bansal<br />
<b>Arxiv Preprint</b><br /> 
[<a href="#" onclick="$('#archiki_sys1x24_abstract').toggle();return false;" style="font-variant: small-caps;">abstract</a>] [<a href="https://github.com/swarnaHub/System-1.x" style="font-variant: small-caps;">code</a>] 
<div id="archiki_sys1x24_abstract" class="abstract" style="display:none;">
</br>
    <p>
Language models can be used to solve long-horizon planning problems in two distinct modes: a fast 'System-1' mode, directly generating plans without any explicit search or backtracking, and a slow 'System-2' mode, planning step-by-step by explicitly searching over possible actions. While System-2 is typically more effective, it is also more computationally expensive, making it infeasible for long plans or large action spaces. Moreover, isolated System-1 or 2 ignores the user's end goals, failing to provide ways to control the model's behavior. To this end, we propose the System-1.x Planner, a controllable planning framework with LLMs that is capable of generating hybrid plans and balancing between the two planning modes based on the difficulty of the problem at hand. System-1.x consists of (i) a controller, (ii) a System-1 Planner, and (iii) a System-2 Planner. Based on a user-specified hybridization factor (x) governing the mixture between System-1 and 2, the controller decomposes a problem into sub-goals, and classifies them as easy or hard to be solved by either System-1 or 2, respectively. We fine-tune all three components on top of a single base LLM, requiring only search traces as supervision. Experiments with two diverse planning tasks -- Maze Navigation and Blocksworld -- show that our System-1.x Planner outperforms a System-1 Planner, a System-2 Planner trained to approximate A* search, and also a symbolic planner (A*). We demonstrate the following key properties of our planner: (1) controllability: increasing the hybridization factor (e.g., System-1.75 vs 1.5) performs more search, improving performance, (2) flexibility: by building a neuro-symbolic variant with a neural System-1 and a symbolic System-2, we can use existing symbolic methods, and (3) generalizability: by being able to learn from different search algorithms, our method is robust to the choice of search algorithm.</p>
  </li>
  <li>
    <p><b><a href="https://arxiv.org/abs/2402.13212">Soft Self-Consistency Improves Language Model Agents</a></b><br/>
Han Wang*, <strong>Archiki Prasad*</strong>, Elias Stengel-Eskin*, and Mohit Bansal<br />
<b><a href="https://2024.aclweb.org/">ACL 2024</a></b><br /> 
[<a href="#" onclick="$('#archiki_softsc24_abstract').toggle();return false;" style="font-variant: small-caps;">abstract</a>] [<a href="https://github.com/HanNight/soft_self_consistency" style="font-variant: small-caps;">code</a>] 
<div id="archiki_softsc24_abstract" class="abstract" style="display:none;">
</br>
    <p>
Generations from large language models (LLMs) can be improved by sampling and scoring multiple solutions to select a final answer. Current "sample and select" methods such as self-consistency (SC) rely on majority voting to score answers. However, when tasks have many distinct and valid answers, selection by voting requires a large number of samples. This makes SC prohibitively expensive for interactive tasks that involve generating multiple actions (answers) sequentially. After establishing that majority voting fails to provide consistent gains on such tasks, we demonstrate how to increase success rates by softening the scoring criterion. We introduce Soft Self-Consistency (Soft-SC), which replaces SC's discontinuous scoring with a continuous score computed from model likelihoods, allowing for selection even when actions are sparsely distributed. Soft-SC improves both performance and efficiency on long-horizon interactive tasks, requiring half as many samples as SC for comparable or better performance. For a fixed number of samples, Soft-SC leads to a 1.3% increase over SC in absolute success rate on writing bash programs, a 6.6% increase on online shopping (WebShop), and a 4.7% increase for an interactive household game (ALFWorld). Finally, we show that Soft-SC can be applied to both open-source and black-box models.</div>
</p>
  </li>
  <li>
    <p><b><a href="https://arxiv.org/abs/2401.16467">ReGAL: Refactoring Programs to Discover Generalizable Abstractions</a></b><br/>
Elias Stengel-Eskin*, <strong>Archiki Prasad*</strong>, and Mohit Bansal<br />
<b><a href="https://icml.cc/Conferences/2024/">ICML 2024</a></b><br /> 
[<a href="#" onclick="$('#archiki_regal24_abstract').toggle();return false;" style="font-variant: small-caps;">abstract</a>] [<a href="https://github.com/esteng/regal_program_learning" style="font-variant: small-caps;">code</a>] 
<div id="archiki_regal24_abstract" class="abstract" style="display:none;">
</br>
    <p>
While large language models (LLMs) are increasingly being used for program synthesis, they lack the global view needed to develop useful abstractions; they generally predict programs one at a time, often repeating the same functionality. Generating redundant code from scratch is both inefficient and error-prone. To address this, we propose Refactoring for Generalizable Abstraction Learning (ReGAL), a gradient-free method for learning a library of reusable functions via code refactorization, i.e. restructuring code without changing its execution output. ReGAL learns from a small set of existing programs, iteratively verifying and refining its abstractions via execution. We find that the shared function libraries discovered by ReGAL make programs easier to predict across diverse domains. On three datasets (LOGO graphics generation, Date reasoning, and TextCraft, a Minecraft-based text game), both open-source and proprietary LLMs improve in accuracy when predicting programs with ReGAL functions. For CodeLlama-13B, ReGAL results in absolute accuracy increases of 11.5% on graphics, 26.1% on date understanding, and 8.1% on TextCraft, outperforming GPT-3.5 in two of three domains. Our analysis reveals ReGAL's abstractions encapsulate frequently-used subroutines as well as environment dynamics.</p>
</div>
</p>
  </li>
  <li>
    <p><b><a href="https://arxiv.org/abs/2311.05772">ADaPT: As-Needed Decomposition and Planning with Language Models</a></b><br/>
<strong>Archiki Prasad</strong>, Alexander Koller, Mareike Hartmann, Peter Clark, Ashish Sabharwal, Mohit Bansal, and Tushar Khot<br />
<b><a href="https://2024.naacl.org/">NAACL 2024</a></b> (Findings)<br /> 
[<a href="#" onclick="$('#archiki_adapt23_abstract').toggle();return false;" style="font-variant: small-caps;">abstract</a>] [<a href="https://github.com/archiki/ADaPT" style="font-variant: small-caps;">code</a>] [<a href="https://allenai.github.io/adaptllm/" style="font-variant: small-caps;">project page</a>]
<div id="archiki_adapt23_abstract" class="abstract" style="display:none;">
</br>
    <p>
Large Language Models (LLMs) are increasingly being used for interactive decision-making tasks requiring planning and adapting to the environment. Recent works employ LLMs-as-agents in broadly two ways: iteratively determining the next action (iterative executors) or generating plans and executing sub-tasks using LLMs (plan-and-execute). However, these methods struggle with task complexity, as the inability to execute any sub-task may lead to task failure. To address these shortcomings, we introduce As-Needed Decomposition and Planning for complex Tasks (ADaPT), an approach that explicitly plans and decomposes complex sub-tasks as-needed, i.e., when the LLM is unable to execute them. ADaPT recursively decomposes sub-tasks to adapt to both task complexity and LLM capability. Our results demonstrate that ADaPT substantially outperforms established strong baselines, achieving success rates up to 28.3% higher in ALFWorld, 27% in WebShop, and 33% in TextCraft -- a novel compositional dataset that we introduce. Through extensive analysis, we illustrate the importance of multilevel decomposition and establish that ADaPT dynamically adjusts to the capabilities of the executor LLM as well as to task complexity.            </p>
</p>
</div>
</p>
  </li>
  <li>
    <p><b><a href="https://arxiv.org/abs/2310.05861">Rephrase, Augment, Reason: Visual Grounding of Questions for Vision-Language Models</a></b><br/>
<strong>Archiki Prasad</strong>, Elias Stengel-Eskin and Mohit Bansal<br />
<b><a href="https://iclr.cc/Conferences/2024/">ICLR 2024</a></b><br /> 
[<a href="#" onclick="$('#archiki_repare23_abstract').toggle();return false;" style="font-variant: small-caps;">abstract</a>] [<a href="https://github.com/archiki/RepARe" style="font-variant: small-caps;">code</a>]
<div id="archiki_repare23_abstract" class="abstract" style="display:none;">
</br>
    <p>
      An increasing number of vision-language tasks can be handled with little to no training, i.e., in a zero and few-shot manner, by marrying large language models (LLMs) to vision encoders, resulting in large vision-language models (LVLMs). While this has huge upsides, such as not requiring training data or custom architectures, how an input is presented to a LVLM can have a major impact on zero-shot model performance. In particular, inputs phrased in an underspecified way can result in incorrect answers due to factors like missing visual information, complex implicit reasoning, or linguistic ambiguity. Therefore, adding visually grounded information to the input as a preemptive clarification should improve model performance by reducing underspecification, e.g., by localizing objects and disambiguating references. Similarly, in the VQA setting, changing the way questions are framed can make them easier for models to answer. To this end, we present Rephrase, Augment and Reason (RepARe), a gradient-free framework that extracts salient details about the image using the underlying LVLM as a captioner and reasoner, in order to propose modifications to the original question. We then use the LVLM's confidence over a generated answer as an unsupervised scoring function to select the rephrased question most likely to improve zero-shot performance. Focusing on three visual question answering tasks, we show that RepARe can result in a 3.85% (absolute) increase in zero-shot accuracy on VQAv2, 6.41%, and 7.94% points increase on A-OKVQA, and VizWiz respectively. Additionally, we find that using gold answers for oracle question candidate selection achieves a substantial gain in VQA accuracy by up to 14.41%. Through extensive analysis, we demonstrate that outputs from RepARe increase syntactic complexity, and effectively utilize vision-language interaction and the frozen language model in LVLMs.
    </p>
</div>
</p>
  </li>
  <li>
    <p><b><a href="https://arxiv.org/abs/2304.10703">ReCEval: Evaluating Reasoning Chains via Correctness and Informativeness</a></b><br/>
<strong>Archiki Prasad</strong>, Swarnadeep Saha, Xiang Zhou and Mohit Bansal<br />
<b><a href="https://2023.emnlp.org/">EMNLP 2023</a></b><br /> 
[<a href="#" onclick="$('#archiki_receval23_abstract').toggle();return false;" style="font-variant: small-caps;">abstract</a>] [<a href="https://github.com/archiki/ReCEval" style="font-variant: small-caps;">code</a>]
<div id="archiki_receval23_abstract" class="abstract" style="display:none;">
</br>
    <p>
      Multi-step reasoning ability is fundamental to many natural language tasks, yet it is unclear what constitutes a good reasoning chain and how to evaluate them. Most existing methods focus solely on whether the reasoning chain leads to the correct conclusion, but this answer-oriented view may confound the quality of reasoning with other spurious shortcuts to predict the answer. To bridge this gap, we evaluate reasoning chains by viewing them as informal proofs that derive the final answer. Specifically, we propose ReCEval (Reasoning Chain Evaluation), a framework that evaluates reasoning chains through two key properties: (1) correctness, i.e., each step makes a valid inference based on the information contained within the step, preceding steps, and input context, and (2) informativeness, i.e., each step provides new information that is helpful towards deriving the generated answer. We implement ReCEval using natural language inference models and information-theoretic measures. On multiple datasets, ReCEval is highly effective in identifying different types of errors, resulting in notable improvements compared to prior methods. We demonstrate that our informativeness metric captures the expected flow of information in high-quality reasoning chains and we also analyze the impact of previous steps on evaluating correctness and informativeness. Finally, we show that scoring reasoning chains based on ReCEval can improve downstream performance of reasoning tasks.
            </p>
</div>
</p>
  </li>
  <li>
    <p><b><a href="https://aclanthology.org/2023.acl-long.837/">MeetingQA: Extractive Question-Answering on Meeting Transcripts</a></b><br/>
<strong>Archiki Prasad</strong>, Trung Bui, Seunghyun Yoon, Hanieh Deilamsalehy, Franck Dernoncourt and Mohit Bansal<br />
<b><a href="https://2023.aclweb.org/">ACL 2023</a></b><br /> 
[<a href="#" onclick="$('#archiki_meetQA23_abstract').toggle();return false;" style="font-variant: small-caps;">abstract</a>] [<a href="https://github.com/adobe-research/meetingqa/" style="font-variant: small-caps;">code + data</a>] [<a href="https://archiki.github.io/meetingqa.html" style="font-variant: small-caps;">project page</a>]
<div id="archiki_meetQA23_abstract" class="abstract" style="display:none;">
</br>
    <p>
      With the ubiquitous use of online meeting platforms and robust automatic speech recognition systems, meeting transcripts have emerged as a new and interesting domain for natural language tasks. Most recent works on meeting transcripts are restricted to summarization and extraction of action items. However, meeting discussions also have a useful question-answering (QA) component, crucial to understanding the discourse or meeting content, and can be used to build interactive interfaces on top of long transcripts. Hence, in this work, we leverage this inherent QA component of meeting discussions and introduce MeetingQA, an extractive QA dataset comprising questions asked by meeting participants and corresponding responses. As a result, questions can be open-ended and seek active discussions, while the answers can be multi-span and spread across multiple speakers. Our comprehensive empirical study of several robust baselines including long-context language models and recent instruction-tuned models reveals that models perform poorly on this task (F1 = 57.3) and severely lag behind human performance (F1 = 84.6), thus presenting a useful, challenging new task for the community to improve upon.
            </p>
</div>
</p>
  </li>
  <li>
    <p><b><a href="https://archiki.github.io/files/EACLCameraReady.pdf">GrIPS: Gradient-free, Edit-based Instruction Search for Prompting Large Language Models</a></b> <br />
<strong>Archiki Prasad</strong>, Peter Hase, Xiang Zhou and Mohit Bansal<br />
<b><a href="https://2023.eacl.org/">EACL 2023</a></b><br /> 
[<a href="#" onclick="$('#archiki_grips22_abstract').toggle();return false;" style="font-variant: small-caps;">abstract</a>] [<a href="https://github.com/archiki/GrIPS" style="font-variant: small-caps;">code</a>]
<div id="archiki_grips22_abstract" class="abstract" style="display:none;">
</br>
    <p>
      Providing natural language instructions in prompts is a useful new paradigm for improving task performance of large language models in a zero-shot setting. Recent work has aimed to improve such prompts via manual rewriting or gradient-based tuning. However, manual rewriting is time-consuming and requires subjective interpretation, while gradient-based tuning can be extremely computationally demanding for large models and requires full access to model weights, which may not be available for API-based models. In this work, we introduce Gradient-free Instructional Prompt Search (GrIPS), a gradient-free, edit-based search approach for improving task instructions for large language models. GrIPS takes in instructions designed for humans and automatically returns an improved, edited prompt, while allowing for API-based tuning. The instructions in our search are iteratively edited using four operations (delete, add, swap, paraphrase) on text at the phrase-level. With InstructGPT models, GrIPS improves the average task performance by up to 4.30 percentage points on eight classification tasks from the Natural-Instructions dataset (with similar improvements
for OPT, BLOOM, and FLANT5). We see improvements for both instruction-only prompts and for k-shot example+instruction prompts. Notably, GrIPS outperforms manual rewriting following the guidelines in Mishra et al. (2022) and also outperforms purely example-based prompts while controlling for the available compute and data budget. Further, performance of GRIPS is
comparable to select gradient-based tuning approaches. Qualitatively, we show our edits can simplify instructions and at times make them incoherent but nonetheless improve accuracy.
            </p>
</div>
</p>
  </li>

  <li>
    <p><b><a href="https://aclanthology.org/2021.mrl-1.16.pdf">The Effectiveness of Intermediate-Task Training for Code-Switched Natural Language Understanding</a></b> <br />
<strong>Archiki Prasad*</strong>, Mohammad Ali Rehan*, Shreya Pathak* and Preethi Jyothi<br />
<b><a href="https://sites.google.com/view/mrl-2021/home">Workshop on Multilingual Representation Learning (MRL) 2021</a>, <a href="https://2021.emnlp.org/">EMNLP 2021</a> </b><br /> 
<strong>🏆 Best Paper Honorable Mention</strong><br />
[<a href="#" onclick="$('#archiki_cos21_abstract').toggle();return false;" style="font-variant: small-caps;">abstract</a>] [<a href="https://github.com/archiki/Intermediate-Task-Code-Switching" style="font-variant: small-caps;">code</a>] [<a href="https://archiki.github.io/files/EMNLP_MRL.pptx" style="font-variant: small-caps">slides</a>]
<div id="archiki_cos21_abstract" class="abstract" style="display:none;">
</br>
    <p>
      While recent benchmarks have spurred a lot of new work on improving the generalization of pretrained multilingual language models on multilingual tasks, techniques to improve code-switched natural language understanding tasks have been far less explored. In this work, we propose the use of bilingual intermediate pretraining as a reliable technique to derive large and consistent performance gains on three different NLP tasks using code-switched text. We achieve substantial absolute improvements of 7.87%, 20.15%, and 10.99%, on the mean accuracies and F1 scores over previous state-of-the-art systems for Hindi-English Natural Language Inference (NLI), Question Answering (QA) tasks, and Spanish-English Sentiment Analysis (SA) respectively. We show consistent performance gains on four different code-switched language-pairs (Hindi-English, Spanish-English, Tamil-English and Malayalam-English) for SA. We also present a code-switched masked language modelling (MLM) pretraining technique that consistently benefits SA compared to standard MLM pretraining using real code-switched text.
            </p>
</div>
</p>
  </li>

  <li>
    <p><b><a href="https://arxiv.org/pdf/2102.06237.pdf">An Investigation of End-to-End Models for Robust Speech Recognition</a></b> <br />
  <strong>Archiki Prasad</strong>, Preethi Jyothi and Rajbabu Velmurugan<br />
  <b><a href="https://2021.ieeeicassp.org/">IEEE-ICASSP 2021</a></b><br /> 
  [<a href="#" onclick="$('#archiki_icassp21_abstract').toggle();return false;" style="font-variant: small-caps;">abstract</a>] [<a href="https://github.com/archiki/Robust-E2E-ASR" style="font-variant: small-caps;">code</a>] [<a href="https://archiki.github.io/files/ICASSPposter.pdf" style="font-variant: small-caps">poster</a>]
  <div id="archiki_icassp21_abstract" class="abstract" style="display:none;">
  </br>
      <p>
          End-to-end models for robust automatic speech recognition (ASR) have not been sufficiently well-explored in prior work. With end-to-end models, one could choose to preprocess the input speech using speech enhancement techniques and train the model using enhanced speech. Another alternative is to pass the noisy speech as input and modify the model architecture to adapt to noisy speech. A systematic comparison of these two approaches for end-to-end robust ASR has not been attempted before. We address this gap and present a detailed comparison of speech enhancement-based techniques and three different model-based adaptation techniques covering data augmentation, multi-task learning, and adversarial learning for robust ASR. While adversarial learning is the best-performing technique on certain noise types, it comes at a cost of degrading clean speech WER. On other relatively stationary noise types, a new speech enhancement technique outperformed all the model-based daptation techniques. This suggests that knowledge of the underlying noise type can meaningfully inform the choice of adaptation technique.
              </p>
  </div>
  </p>
    </li>

    <li>
      <p><b><a href="https://archiki.github.io/files/wcnc-prasad.pdf">Decentralized Age-of-Information Bandits</a></b><br />
    <strong>Archiki Prasad</strong>, Vishal Jain and Sharayu Moharir<br />
    <b><a href="https://wcnc2021.ieee-wcnc.org/">IEEE-WCNC 2021</a></b><br /> 
    [<a href="#" onclick="$('#archiki_wcnc21_abstract').toggle();return false;" style="font-variant: small-caps;">abstract</a>] [<a href="https://arxiv.org/pdf/2009.12961.pdf" style="font-variant: small-caps;">long-form with proofs</a>]
    <div id="archiki_wcnc21_abstract" class="abstract" style="display:none;">
    </br>
        <p>
            Age-of-Information (AoI) is a performance metric for scheduling systems that measures the freshness of the data available at the intended destination. AoI is formally defined as the time elapsed since the destination received the recent most update from the source. We consider the problem of scheduling to minimize the cumulative AoI in a multi-source multi-channel setting. Our focus is on the setting where channel statistics are unknown and we model the problem as a distributed multi-armed bandit problem. For an appropriately defined AoI regret metric, we provide analytical performance guarantees of an existing UCB-based policy for the distributed multi-armed bandit problem. In addition, we propose a novel policy based on Thomson Sampling and a hybrid policy that tries to balance the trade-off between the aforementioned policies. Further, we develop AoI-aware variants of these policies in which each source takes its current AoI into account while making decisions. We compare the performance of various policies via simulations. 
        </p>
    </div>
    </p>
      </li>
      
  <li>
    <p><b><a href="https://www.aclweb.org/anthology/2020.acl-main.345.pdf">How Accents Confound: Probing for Accent Information in End-to-End Speech Recognition Systems</a></b><br />
 <strong>Archiki Prasad</strong> and Preethi Jyothi<br />
 <b><a href="https://www.aclweb.org/anthology/volumes/2020.acl-main/">ACL 2020</a></b><br /> 
<!-- [<a href="#archiki_acl20_bib">bib</a>] -->
[<a href="#" onclick="$('#archiki_acl20_abstract').toggle();return false;" style="font-variant: small-caps;">abstract</a>]                          
[<a href="https://github.com/archiki/ASR-Accent-Analysis" style="font-variant: small-caps;">code</a>] [<a href="https://slideslive.com/38929438/how-accents-confound-probing-for-accent-information-in-endtoend-speech-recognition-systems" style="font-variant: small-caps;">talk</a>]
<div id="archiki_acl20_abstract" class="abstract" style="display:none;">
</br>
    <p>
        In this work, we present a detailed analysis of how accent information is reflected in the internal representation of speech in an end-to-end automatic speech recognition (ASR) system. We use a state-of-the-art end-to-end ASR system, comprising convolutional and recurrent layers, that is trained on a large amount of US-accented English speech and evaluate the model on speech samples from seven different English accents. We examine the effects of accent on the internal representation using three main probing techniques: a) Gradient-based explanation methods, b) Information-theoretic measures, and c) Outputs of accent and phone classifiers. We find different accents exhibiting similar trends irrespective of the probing technique used. We also find that most accent information is encoded within the first recurrent layer, which is suggestive of how one could adapt such an end-to-end model to learn representations that are invariant to accents.
    </p>
</div>
</p>

  </li>
  <li>
    <p><b><a href="https://dl.acm.org/doi/pdf/10.1145/3366424.3382728">Time Series Forecasting for Cold-Start Items by Learning from Related Items using Memory Networks</a></b><br />
Ayush Chauhan, <strong>Archiki Prasad</strong>, Parth Gupta, Amiredddy Prashanth Reddy and Shiv Kumar Saini<br />
<b><a href="https://www2020.thewebconf.org/">The Web Conference (WWW) 2020 </a></b><br /> 
[<a href="#" onclick="$('#archiki_www20_abstract').toggle();return false;" style="font-variant: small-caps;">abstract</a>]
<div id="archiki_www20_abstract" class="abstract" style="display:none;">
</br>
    <p>
        Time series forecasting for new items is very important in a wide variety of applications. Existing solutions for time series forecasting, however, do not address this cold start problem. The underlying machine learning models in these solutions rely heavily on the availability of the past data points of the time series. Here, we propose to use a modified Dynamic Key-Value Memory Network (DKVMN) that enables knowledge sharing across items. The network is conventionally used for binary tasks in knowledge tracing. We modify it for our regression-based forecasting use-case. Specifically, we change the output layer, include feedback for error correction, add a mechanism to handle scale across items. We test our solution on the SKU level data of a large e-commerce company and compare the results to the widely used LSTM model, outperforming it by over 25% across multiple metrics.
    </p>
</div>
</p>
  </li>
  <li>
    <p><b><a href="https://uspto.report/patent/app/20210350175">Key-Value Memory Networks for Predicting Time Series Metrics of Target Entities</a></b><br />
Shiv Kumar Saini, Ayush Chauhan, Parth Gupta, <strong>Archiki Prasad</strong>, Amiredddy Prashanth Reddy and Ritwick Chaudhary <br />
<em>Patent filed at the </em><b><a href="https://www.uspto.gov/">US Patent and Trademarks Office</a></b> <em>2020 | Adobe Inc.</em><br />
[<a href="#" onclick="$('#archiki_patent').toggle();return false;" style="font-variant: small-caps;">summary</a>] [<a href="https://patents.google.com/patent/US20210350175A1/en" style="font-variant: small-caps;">application no.<small> US16/868942</small></a>]
<div id="archiki_patent" class="abstract" style="display:none;">
</br>
    <p>
        This disclosure involves using key-value memory networks to predict time-series data. For instance, a computing system retrieves, for a target entity, static feature data and target time-series feature data. The computing system can normalize the target time-series feature data based on a normalization scale. The computing system also generates input data by, for example, concatenating the static feature data, the normalized time-series feature data, and time-specific feature data. The computing system generates predicted time-series data for the target metric of the target entity by applying a key-value memory network to the input data. The key-value memory network can include a key matrix learned from training static feature data and training time-series feature data, a value matrix representing time-series trends, and an output layer with a continuous activation function for generating predicted time-series data.
    </p>
</div>
</p>
  </li>
  
  

</ul>

<!-- <p><sup>†</sup><em>Equal Contribution</em></p> -->

<h3 id="research-projects">Research Projects</h3>
Please have a look at my <a href="/files/CV.pdf">Curriculum Vitae</a> for a comprehensive list of my projects.
<!--
<h4 id="2020">2020</h4>
<p><b>Adapting Multilingual BERT for Code-Switching</b> <br/>
<em>Guide: <a href="https://www.cse.iitb.ac.in/~pjyothi/">Prof. Preethi Jyothi</a>, <a href="http://www.iitb.ac.in/">IIT Bombay</a></em></p>

<p><strong style="color:#800000;">> What is code-switching?</strong> Code-Switching occurs when more than one language is used in the same text or conversation. For languages with differenct scripts such as English-Hindi, code-switched data may be in the native script, eg. <strong>Weekend</strong> का क्या <strong>plan</strong> है<strong>?</strong>, or transliterated in the roman script, eg. <strong>Weekend ka kya plan hai?</strong><br/>
<strong style="color:#800000;">> Why is this problem important?</strong> A majority of english speakers around the world are non-native speakers and thus, speak more than one language. For such speakers, there is a tendency to switch between two languages in informal verbal and textual settings such as conversations, social-media posts. However, NLP systems struggle to understand such text. Bridging this gap will enable these systems to have a larger reach.<br/>
<strong style="color:#800000;">Note: I have removed the project description in honor of the anonymity period of an ongoing submission. Please reach out to me in case of any queries.</strong>

</p>

<p><b>Joint Noise and Accent Robustness of End-to-End ASR</b><br/>
<em>Guide: <a href="https://www.cse.iitb.ac.in/~pjyothi/">Prof. Preethi Jyothi</a> and <a href="https://www.ee.iitb.ac.in/wiki/faculty/rajbabu">Prof. Rajbabu Velmurugan</a>, <a href="http://www.iitb.ac.in/">IIT Bombay</a></em></p>

<strong style="color:#800000;">> Why is this problem important?</strong> End-to-end speech recognition datasets are often curated for native speakers in quiet surroundings. In the real-world deployment of these systems, more often than not the speakers have non-native accented speech in the presence of background noise. This out-of-distribution data causes very high degradation in real-world performance.<br/>
<strong style="color:#800000;">> Our focus</strong> is to develop training techniques that can adapt ASR systems trained on clean native speech using low-resource noisy and accented speech. So far, we have been able to show simple machine learning techniques like multi-task learning and adversarial training on end-to-end systems can outperform or match the performance of the state-of-the-art front-end speech enhancement used to tackle noisy speech.
</p>

<p><b>Decentralized Scheduling via Age-of-Information (AoI) Bandits</b><br/>
<em>Guide: <a href="https://www.ee.iitb.ac.in/web/people/faculty/home/sharayum">Prof. Sharayu Moharir</a>,  <a href="http://www.iitb.ac.in/">IIT Bombay</a></em></p>

<p><strong style="color:#800000;">> What is Age-of-Information?</strong> Age-of-Information (AoI) is a performance metric for scheduling systems that measures the freshness of the data available at the intended destination. AoI is formally defined as the time elapsed since the destination received the recent most update from the source. In our case, we minimize the total AoI of a network of sources.<br/>
<strong style="color:#800000;">> Why is this problem important?</strong> With an increasing number of IoT devices, there are several applications in which a large network of (decentralized) devices or sensors need to communicate to a control center using a limited number of channels. In many cases, heavily delayed information is not useful in the decision making of the main control center. The definition of AoI captures this constraint and minimizing this metric is mre challenging than maximizing a bernoulli reward. <br/>
<strong style="color:#800000;">> Our focus</strong> was to use multi-armed bandits to adress this scheduling problem. We have extended scheduling algorithms using Upper Confidence Bound and Thompson Sampling to minimize the AoI and proposed a novel hybrid policy. We have also made metric-aware modifications that further minimize regret. 
</p>

<h4 id="2019">2019</h4>

<p><b>Probing End-to-End ASR for Accent Information</b><br/>
<em>Guide: <a href="https://www.cse.iitb.ac.in/~pjyothi/">Prof. Preethi Jyothi</a>,  <a href="http://www.iitb.ac.in/">IIT Bombay</a></em></p>

<p><strong style="color:#800000;">> What is the effect of accents on ASR?</strong> Most of the standard speech recognition datasets contain speech from only native english speakers often in the American accent. Systems trained on such datasets tend to underperform when subjected to new accent such as UK or Australian English. This performance gap further widens for thick accents such as Indian or Scottish English.<br/>
<strong style="color:#800000;">> Why is this problem important?</strong> Due to the performance disparity and the large number of non-native speakers the problem of accent adaptation has recieved a lot of attention. However, as the field has moved towards end-to-end models that are opaque, there is very limited understanding about how the effect of accents manifests in these networks. Progress in understanding this model behaviour will not only reveal the defects in these systems but can also inform adaptation techniques.<br/>
<strong style="color:#800000;">> Our focus</strong> was to understand how this effect manifests in a renowned end-to-end ASR system called DeepSpeech2. We use a lot of popular interpretability techniques such a saliency maps, information-theoretic measures and probing classifiers that shed light on the model behaviour and how it changes for different accents.

<p><b>Time Series Forecasting of Cold-Start Entities</b><br/>
<em>Guide: <a href="https://research.adobe.com/person/shiv-kumar-saini/">Dr. Shiv Saini</a>, <a href="https://research.adobe.com/">Adobe Research</a> (Internship)</em></p>

<p><strong style="color:#800000;">> What are cold-start entities/products?</strong> These are products that have little or no historical data. Often, newly launched products fit into this category.</strong><br/>
<strong style="color:#800000;">> Why is this problem important?</strong> Most machine learning-based solutions for time-series forecasting rely on historical sequential data and fail to generate any reasonable forecasts for cold-start products. At the same time, these forecasts for these products are extremely valuable to end-users like analysts to make crucial decisions early into the product life-cycle and manage inventory.<br/>
<strong style="color:#800000;">> Our focus</strong> was to design a framework that maximizes learning between cold-start and data-rich products and use all the textual meta-information available about the product. For this we used a Key-Value Memory network which reinforces cross-learning and outperforms the LSTM baseline. An additional goal of this project was to track the products that were similar as per the model at different time steps.
-->


  </div>

  <!--div class="date">
    Written on 
  </div
//-->

  
</article>
</div>

    <div class="wrapper-footer">
      <div class="container">
        <footer class="footer">
<!-- <div style="float:left;color:#808080">Archiki Prasad<br style="clear:both" /> </div> -->
<div class="row">
<div class="column"><a style="float:left;color:#808080"><span>Archiki Prasad</span></a>
<br style="clear:both" />
<a href="mailto:archikiprasad@gmail.com" style="float:left;font-weight:lighter;"><span>archikiprasad@gmail.com</span></a>
<br style="clear:both" />
<a href="mailto:archiki@cs.unc.edu" style="float:left;font-weight:lighter;"><span>archiki@cs.unc.edu</span></a>
</div>
<!-- <div class="row"> -->
<div class="column">
<a href="https://github.com/archiki" style="float:left;font-weight:lighter;"><span class="icon icon--github"><svg x="0px" y="0px" width="16px" height="16px" viewBox="0 0 16 16"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">archiki</span></a>
<br style="clear:both" />
<a href="https://www.linkedin.com/in/archiki-prasad" style="float:left;font-weight:lighter;"><span class="icon icon--linkedin"><svg  x="0px" y="0px" width="16px" height="16px" viewBox="0 -20 512 512"><path fill="#828282" d="M150.65,100.682c0,27.992-22.508,50.683-50.273,50.683c-27.765,0-50.273-22.691-50.273-50.683
    C50.104,72.691,72.612,50,100.377,50C128.143,50,150.65,72.691,150.65,100.682z M143.294,187.333H58.277V462h85.017V187.333z
    M279.195,187.333h-81.541V462h81.541c0,0,0-101.877,0-144.181c0-38.624,17.779-61.615,51.807-61.615
    c31.268,0,46.289,22.071,46.289,61.615c0,39.545,0,144.181,0,144.181h84.605c0,0,0-100.344,0-173.915
    s-41.689-109.131-99.934-109.131s-82.768,45.369-82.768,45.369V187.333z"/></svg></span><span class="username">&nbsp;Archiki Prasad</span></a>
<br style="clear:both" />
<a href="https://www.twitter.com/archikiprasad" style="float:left;font-weight:lighter;"><span class="icon icon--twitter"><svg x="0px" y="0px" width="16px" height="16px" viewBox="0 -6 20 20"><path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"></path>
</svg></span><span class="username">&nbsp;ArchikiPrasad</span></a>

</div>
</div>

        </footer>
      </div>
    </div>

    

  </body>
</html>

